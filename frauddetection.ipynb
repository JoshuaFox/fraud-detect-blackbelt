{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt   \n",
    "#from IPython.display import Image                 \n",
    "##from IPython.display import display               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket:\n",
      "fraudjf\n",
      "CPU times: user 638 ms, sys: 44 ms, total: 682 ms\n",
      "Wall time: 682 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "#session = sagemaker.Session()#TODO restore\n",
    "#region = session.boto_region_name#TODO restoe\n",
    "bucket = 'fraudjf'\n",
    " \n",
    "prefix = 'sagemaker/xgboost'\n",
    "#role = sagemaker.get_execution_role()#TODO Restor\n",
    "\n",
    "print('Bucket:\\n{}'.format(bucket))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 44480\n",
      "CPU times: user 4.1 s, sys: 91.5 ms, total: 4.19 s\n",
      "Wall time: 4.2 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>2803.83</td>\n",
       "      <td>C1129433283</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M864138492</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>5581.55</td>\n",
       "      <td>C997695567</td>\n",
       "      <td>530.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1282788025</td>\n",
       "      <td>55058.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_IN</td>\n",
       "      <td>161632.16</td>\n",
       "      <td>C725832346</td>\n",
       "      <td>310651.04</td>\n",
       "      <td>472283.20</td>\n",
       "      <td>C985934102</td>\n",
       "      <td>1044238.89</td>\n",
       "      <td>971418.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>113283.13</td>\n",
       "      <td>C407148497</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C885951223</td>\n",
       "      <td>123001.91</td>\n",
       "      <td>215851.28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>8092.10</td>\n",
       "      <td>C1856093404</td>\n",
       "      <td>1302.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M123337428</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44475</th>\n",
       "      <td>718</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>1864.24</td>\n",
       "      <td>C49652609</td>\n",
       "      <td>20426.00</td>\n",
       "      <td>18561.76</td>\n",
       "      <td>C1799009964</td>\n",
       "      <td>188746.00</td>\n",
       "      <td>190610.24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44476</th>\n",
       "      <td>720</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>71439.81</td>\n",
       "      <td>C170506678</td>\n",
       "      <td>71439.81</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1141419100</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44477</th>\n",
       "      <td>725</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>873322.61</td>\n",
       "      <td>C488866911</td>\n",
       "      <td>873322.61</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C850044970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44478</th>\n",
       "      <td>730</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>403.56</td>\n",
       "      <td>C1494188706</td>\n",
       "      <td>403.56</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C1175598908</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44479</th>\n",
       "      <td>737</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>1281113.84</td>\n",
       "      <td>C2044735759</td>\n",
       "      <td>1281113.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C2118381511</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>44480 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       step      type      amount     nameOrig  oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud\n",
       "0         1   PAYMENT     2803.83  C1129433283           0.00            0.00   M864138492            0.00            0.00        0               0\n",
       "1         1     DEBIT     5581.55   C997695567         530.00            0.00  C1282788025        55058.57            0.00        0               0\n",
       "2         1   CASH_IN   161632.16   C725832346      310651.04       472283.20   C985934102      1044238.89       971418.91        0               0\n",
       "3         1  CASH_OUT   113283.13   C407148497           0.00            0.00   C885951223       123001.91       215851.28        0               0\n",
       "4         1   PAYMENT     8092.10  C1856093404        1302.00            0.00   M123337428            0.00            0.00        0               0\n",
       "...     ...       ...         ...          ...            ...             ...          ...             ...             ...      ...             ...\n",
       "44475   718     DEBIT     1864.24    C49652609       20426.00        18561.76  C1799009964       188746.00       190610.24        0               0\n",
       "44476   720  TRANSFER    71439.81   C170506678       71439.81            0.00  C1141419100            0.00            0.00        1               0\n",
       "44477   725  TRANSFER   873322.61   C488866911      873322.61            0.00   C850044970            0.00            0.00        1               0\n",
       "44478   730  TRANSFER      403.56  C1494188706         403.56            0.00  C1175598908            0.00            0.00        1               0\n",
       "44479   737  TRANSFER  1281113.84  C2044735759     1281113.84            0.00  C2118381511            0.00            0.00        1               0\n",
       "\n",
       "[44480 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import pandas as pd\n",
    "raw_data_filename = 'fraud-detection.csv'\n",
    "\n",
    "#s3 = boto3.resource('s3', region_name=region)\n",
    "#s3.Bucket(bucket).download_file(raw_data_filename, raw_data_filename)\n",
    "percent_to_read=0.7\n",
    "fraction_to_read=percent_to_read/100 # Divide by 1000 and not 100 as expected?\n",
    "nrows=10_000_000# There are 6.3 million lines in the original\n",
    "df = pd.read_csv('./'+raw_data_filename,nrows=nrows, skiprows=lambda i: i>0 and random.random() > fraction_to_read)\n",
    "pd.set_option('display.max_rows', 10) \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print('Length', len(df))\n",
    "target_col='isFraud'\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud 55 Not fraud 44425 total 44480\n"
     ]
    }
   ],
   "source": [
    "fraud_len=len(  df.loc[  df['isFraud']  ==1  ])\n",
    "not_fraud_len=len(df)-fraud_len\n",
    "print('Fraud', fraud_len, 'Not fraud', not_fraud_len, \"total\", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['isFlaggedFraud'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt   \n",
    "\n",
    "val_counts=df[target_col].value_counts()\n",
    "val_counts=val_counts.apply(lambda x: math.log(x,10))\n",
    "plt.bar(['Yes', 'No'], val_counts)\n",
    "plt.ylabel('log count')\n",
    "\n",
    "plt.show()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols.remove(target_col)\n",
    "\n",
    "cols = [target_col] + cols\n",
    "\n",
    "df = df[cols]# Move target to the left\n",
    "\n",
    "df_dummies=pd.get_dummies(df['type'],drop_first=True )\n",
    "\n",
    "df=df.drop(['type'], axis=1)\n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#%pip install category_encoders\n",
    "\n",
    "import category_encoders as ce  \n",
    "hashencode_these = ['nameOrig', 'nameDest']\n",
    "columns_before = [x for x in df.columns if x not in hashencode_these+[target_col]]\n",
    "\n",
    "def make_col_mapping(cols):\n",
    "    col_mapping = {}\n",
    "    for c in cols:\n",
    "        if c[:4]=='col_':\n",
    "          num = c.split('_')[-1]\n",
    "          int(num) # check format\n",
    "          col_mapping[c] = hashencode_this + \"_\" + num\n",
    "     \n",
    "    return col_mapping\n",
    "\n",
    "\n",
    "def hashencode(hashencode_this, df, previous_hash_cols):\n",
    "    for c in df.columns:\n",
    "        assert c[:4]!=\"col_\",  df.columns\n",
    "                \n",
    "    ce_hash = ce.HashingEncoder(cols = [hashencode_this])\n",
    "    X1 = df.drop([target_col], axis=1)\n",
    "    y1 = df.isFraud\n",
    "    with_hashing = ce_hash.fit_transform(X1, y1)\n",
    "    hashed = with_hashing.drop(columns_before+previous_hash_cols, axis=1)\n",
    "    generated_cols = [x for x in hashed.columns if x[:4]=='col_']\n",
    "    col_mapping = make_col_mapping(generated_cols)\n",
    "    \n",
    "    hashed = hashed.rename(columns = col_mapping)\n",
    "    df = pd.concat([y1, X1, hashed], axis=1)\n",
    " \n",
    "    df = df.drop([hashencode_this], axis=1)\n",
    "    return df, list(col_mapping.values())\n",
    " \n",
    "previous_hash_cols = []\n",
    "for hashencode_this in hashencode_these: \n",
    "   df, previous_hash_cols = hashencode(hashencode_this,df,previous_hash_cols)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install imbalanced-learn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "smote = SMOTE(random_state = 101)\n",
    "\n",
    "ycol='isFraud'\n",
    "Xcol=list(df.columns)\n",
    "Xcol.remove(ycol)\n",
    "X, y = smote.fit_resample(df[Xcol], df[ycol])\n",
    "#Creating a new Oversampling Data Frame\n",
    "df_oversampler = pd.DataFrame(X, columns = Xcol)\n",
    "df_oversampler['Exited']\n",
    "sns.countplot(df_oversampler['Exited'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "len_=len(df)\n",
    "\n",
    "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len_), int(0.9 * len_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's version of XGBoost supports input data in both CSV and libSVM data format.  We'll use libSVM here, with features and the target variable provided as separate arguments. To avoid any misalignment issues due to random reordering, this split is done after the previous split in the above cell. As a last step before training, we'll copy the resulting files to S3 as input for Amazon SageMaker's hosted training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file   \n",
    "\n",
    "for d in [(train_data, 'train.libsvm'), ( validation_data, 'validation.libsvm'), (test_data, 'test.libsvm')]:\n",
    "   dataset=d[0]\n",
    "   dump_svmlight_file(X=dataset.drop(['isFraud', 'isFlaggedFraud'], axis=1), y=dataset['isFraud'], f=d[1])\n",
    "\n",
    "for filename in ['train.libsvm' 'validation.libsvm']:\n",
    "   s3.Bucket(bucket).Object(prefix + '/'+filename.split['.'][0]+'/'+filename).upload_file(f)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_path(subset):\n",
    "  return sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(bucket, prefix,subset), content_type='libsvm')\n",
    "\n",
    "s3_input_train = s3_path('train')\n",
    "s3_input_validation =s3_path('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Our data is now ready to be used to train a XGBoost model. The XGBoost algorithm has many tunable hyperparameters. Some of these hyperparameters are listed below; initially we'll only use a few of them.  \n",
    "\n",
    "- `max_depth`: Maximum depth of a tree. As a cautionary note, a value too small could underfit the data, while increasing it will make the model more complex and thus more likely to overfit the data (in other words, the classic bias-variance tradeoff).\n",
    "- `eta`: Step size shrinkage used in updates to prevent overfitting.  \n",
    "- `eval_metric`: Evaluation metric(s) for validation data. For data sets such as this one with imbalanced classes, we'll use the AUC metric.\n",
    "- `scale_pos_weight`: Controls the balance of positive and negative weights, again useful for data sets having imbalanced classes.\n",
    "\n",
    "First we'll set up the parameters for an Amazon SageMaker Estimator object, and the hyperparameters for the algorithm itself.  The Estimator object from the Amazon SageMaker Python SDK is a convenient way to set up training jobs with a minimal amount of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(region, 'xgboost','1.0-1')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    base_job_name='fraud-detection-job',\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.c5.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=3,\n",
    "                        eta=0.1,\n",
    "                        subsample=0.5,\n",
    "                        eval_metric='auc',\n",
    "                        objective='binary:logistic',\n",
    "                        scale_pos_weight=2.0,\n",
    "                        num_round=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll run the hosted training job itself.  The hardware used for the training job is separate from your notebook instance and is managed by Amazon SageMaker, which performs the heavy lifting such as setting up a training cluster and tearing it down when the job is done.  A single line of code starts the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the XGBoost algorithm on our data, we can deploy the trained model to an Amazon SageMaker hosted endpoint with one simple line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "                          instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Now that we have our hosted endpoint, we can generate predictions from it. More specifically, let's generate predictions from our test data set to understand how well our model generalizes to data it has not seen yet.\n",
    "\n",
    "There are many ways to compare the performance of a machine learning model.  We'll start simply by comparing actual to predicted values of whether the ticket was a \"success\" (`1`) or not (`0`).  Then we'll produce a  confusion matrix, which shows how many test data points were predicted by the model in each category versus how many test data points actually belonged in each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/x-libsvm'\n",
    "xgb_predictor.deserializer = None\n",
    "\n",
    "def do_predict(data):\n",
    "    payload = '\\n'.join(data)\n",
    "    response = xgb_predictor.predict(payload).decode('utf-8')\n",
    "    result = response.split(',')\n",
    "    preds = [float((num)) for num in result]\n",
    "    preds = [round(num) for num in preds]\n",
    "    return preds\n",
    "\n",
    "def batch_predict(data, batch_size):\n",
    "    items = len(data)\n",
    "    arrs = []\n",
    "    \n",
    "    for offset in range(0, items, batch_size):\n",
    "        if offset+batch_size < items:\n",
    "            results = do_predict(data[offset:(offset+batch_size)])\n",
    "            arrs.extend(results)\n",
    "        else:\n",
    "            arrs.extend(do_predict(data[offset:items]))\n",
    "        sys.stdout.write('.')\n",
    "    return(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "with open('test.libsvm', 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "labels = [int(line.split(' ')[0]) for line in payload.split('\\n')]\n",
    "test_data = [line for line in payload.split('\\n')]\n",
    "preds = batch_predict(test_data, 100)\n",
    "\n",
    "print ('\\nError rate=%f' % ( sum(1 for i in range(len(preds)) if preds[i]!=labels[i]) /float(len(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=np.array(labels), columns=np.array(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Extensions\n",
    "\n",
    "This XGBoost model is just the starting point for predicting whether a game will be a hit based on reviews and other attributes.  There are several possible avenues for improving the model's performance.  First, of course, would be to collect more data and, if possible, fill in the existing missing fields with actual information.  Another possibility is further hyperparameter tuning using Amazon SageMaker's Automatic Model Tuning feature.  Examples of using this feature can be found in the [hyperparameter tuning directory of the SageMaker Examples GitHub repository](https://github.com/awslabs/amazon-sagemaker-examples/tree/master/hyperparameter_tuning) and the **SageMaker Examples** tab of Amazon SageMaker notebook instances.  And, although ensemble learners often do well with imbalanced data sets, it could be worth exploring techniques for mitigating imbalances such as downsampling, synthetic data augmentation, and other approaches.  \n",
    "\n",
    "---\n",
    "## Cleanup\n",
    "\n",
    "If you are finished with this notebook, please run the cell below. This will remove the hosted endpoint you created and avoid any charges from a stray instance being left on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.delete_endpoint(xgb_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
