{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 1 µs, total: 12 µs\n",
      "Wall time: 16 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import sys;\n",
    "#!{sys.executable} -m pip install -r requirements.txt\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "isConfigCell": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bucket sagemaker-jfox in region eu-west-1\n",
      "CPU times: user 799 ms, sys: 60.6 ms, total: 860 ms\n",
      "Wall time: 2.92 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "session = sagemaker.Session() \n",
    "region = session.boto_region_name \n",
    "\n",
    "bucket = 'sagemaker-jfox'\n",
    " \n",
    "prefix = 'sagemaker/xgboost'\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "print(f'Bucket {bucket} in region {region}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 113\n",
      "CPU times: user 76.1 ms, sys: 4.21 ms, total: 80.3 ms\n",
      "Wall time: 1.08 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>type</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>181.00</td>\n",
       "      <td>C1305486145</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>C553264065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>7817.71</td>\n",
       "      <td>C90045638</td>\n",
       "      <td>53860.0</td>\n",
       "      <td>46042.29</td>\n",
       "      <td>M573487274</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>4024.36</td>\n",
       "      <td>C1265012928</td>\n",
       "      <td>2671.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1176932104</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>1157.86</td>\n",
       "      <td>C1237762639</td>\n",
       "      <td>21156.0</td>\n",
       "      <td>19998.14</td>\n",
       "      <td>M1877062907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>1065.41</td>\n",
       "      <td>C1959239586</td>\n",
       "      <td>1817.0</td>\n",
       "      <td>751.59</td>\n",
       "      <td>C515132998</td>\n",
       "      <td>10330.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>6993.70</td>\n",
       "      <td>C938613108</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M1598898814</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>15034.23</td>\n",
       "      <td>C1059300256</td>\n",
       "      <td>40458.0</td>\n",
       "      <td>25423.77</td>\n",
       "      <td>M1521568953</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>DEBIT</td>\n",
       "      <td>13758.63</td>\n",
       "      <td>C216376974</td>\n",
       "      <td>29858.0</td>\n",
       "      <td>16099.37</td>\n",
       "      <td>C1219161283</td>\n",
       "      <td>21305.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>8419.73</td>\n",
       "      <td>C88301993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>M841166421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>PAYMENT</td>\n",
       "      <td>9738.95</td>\n",
       "      <td>C2031927175</td>\n",
       "      <td>289748.0</td>\n",
       "      <td>280009.05</td>\n",
       "      <td>M176041373</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud  isFlaggedFraud\n",
       "0       1  TRANSFER    181.00  C1305486145          181.0            0.00   C553264065             0.0             0.0        1               0\n",
       "1       1   PAYMENT   7817.71    C90045638        53860.0        46042.29   M573487274             0.0             0.0        0               0\n",
       "2       1   PAYMENT   4024.36  C1265012928         2671.0            0.00  M1176932104             0.0             0.0        0               0\n",
       "3       1   PAYMENT   1157.86  C1237762639        21156.0        19998.14  M1877062907             0.0             0.0        0               0\n",
       "4       1     DEBIT   1065.41  C1959239586         1817.0          751.59   C515132998         10330.0             0.0        0               0\n",
       "..    ...       ...       ...          ...            ...             ...          ...             ...             ...      ...             ...\n",
       "108     1   PAYMENT   6993.70   C938613108            0.0            0.00  M1598898814             0.0             0.0        0               0\n",
       "109     1   PAYMENT  15034.23  C1059300256        40458.0        25423.77  M1521568953             0.0             0.0        0               0\n",
       "110     1     DEBIT  13758.63   C216376974        29858.0        16099.37  C1219161283         21305.0             0.0        0               0\n",
       "111     1   PAYMENT   8419.73    C88301993            0.0            0.00   M841166421             0.0             0.0        0               0\n",
       "112     1   PAYMENT   9738.95  C2031927175       289748.0       280009.05   M176041373             0.0             0.0        0               0\n",
       "\n",
       "[113 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "import random\n",
    "import pandas as pd\n",
    "raw_data_filename = 'fraudhead.csv'\n",
    "\n",
    "s3 = boto3.resource('s3', region_name=region)\n",
    "#s3.Bucket(bucket).download_file(raw_data_filename, raw_data_filename)\n",
    "percent_to_read=10\n",
    "fraction_to_read=percent_to_read/100 # Divide by 1000 and not 100 as expected?\n",
    "df = pd.read_csv('./'+raw_data_filename,  skiprows=lambda i: i>0 and random.random() > fraction_to_read)\n",
    "pd.set_option('display.max_rows', 10) \n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "print('Length', len(df))\n",
    "target_col='isFraud'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counts of each class to determine imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraud 2 ; Not fraud 111 ; Total 113\n"
     ]
    }
   ],
   "source": [
    " \n",
    "def count_positive_and_negative(df):\n",
    "    num_positive = len(df.loc[  df[target_col] == 1 ])\n",
    "    num_negative = len(df) - num_positive\n",
    "    return num_positive, num_negative\n",
    "\n",
    "num_positive, num_negative = count_positive_and_negative(df)\n",
    "\n",
    "print('Fraud', num_positive, '; Not fraud', num_negative, '; Total', len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not using `isFlaggedFraud`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['isFlaggedFraud'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot distribution of positive vs negative, in log scale because of the imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt   \n",
    "def plot_positive_negative_counts(df, target_col):\n",
    "    val_counts=df[target_col].value_counts()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set(yscale=\"log\")\n",
    "    plt.bar(['Yes', 'No'], val_counts)\n",
    "    plt.ylabel('count')\n",
    "    plt.show()\n",
    "    \n",
    "plot_positive_negative_counts(df,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     step      type    amount     nameOrig  oldbalanceOrg  newbalanceOrig     nameDest  oldbalanceDest  newbalanceDest  isFraud\n",
      "0       1  TRANSFER -0.526424  C1305486145      -0.416364       -0.417482   C553264065       -0.390906       -0.401936        1\n",
      "1       1   PAYMENT -0.494391    C90045638      -0.389427       -0.395030   M573487274       -0.390906       -0.401936        0\n",
      "2       1   PAYMENT -0.510303  C1265012928      -0.415115       -0.417482  M1176932104       -0.390906       -0.401936        0\n",
      "3       1   PAYMENT -0.522326  C1237762639      -0.405838       -0.407730  M1877062907       -0.390906       -0.401936        0\n",
      "4       1     DEBIT -0.522714  C1959239586      -0.415543       -0.417116   C515132998       -0.385337       -0.401936        0\n",
      "..    ...       ...       ...          ...            ...             ...          ...             ...             ...      ...\n",
      "108     1   PAYMENT -0.497848   C938613108      -0.416455       -0.417482  M1598898814       -0.390906       -0.401936        0\n",
      "109     1   PAYMENT -0.464122  C1059300256      -0.396152       -0.405085  M1521568953       -0.390906       -0.401936        0\n",
      "110     1     DEBIT -0.469472   C216376974      -0.401472       -0.409632  C1219161283       -0.379421       -0.401936        0\n",
      "111     1   PAYMENT -0.491866    C88301993      -0.416455       -0.417482   M841166421       -0.390906       -0.401936        0\n",
      "112     1   PAYMENT -0.486333  C2031927175      -0.271053       -0.280936   M176041373       -0.390906       -0.401936        0\n",
      "\n",
      "[113 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "columns = df.columns\n",
    "print(columns)\n",
    "numerical_cols = ['amount', 'oldbalanceOrg', 'newbalanceOrig', 'oldbalanceDest', 'newbalanceDest']\n",
    "other_col =[c for c in columns if  c not in numerical_cols]\n",
    "df_other = df[other_col]\n",
    "print(df_other.columns)\n",
    "\n",
    "df_num = df[numerical_cols]\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_num = pd.DataFrame(scaler.fit_transform(df_num), columns=df_num.columns)\n",
    "df = pd.concat([df_num, df_other], axis=1)\n",
    "df = df[columns] # Put back in old order\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dummies (onehot) for `type` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.columns.tolist()\n",
    "cols.remove(target_col)\n",
    "cols = [target_col] + cols\n",
    "df = df[cols] # Move target to the left\n",
    "\n",
    "df_dummies=pd.get_dummies(df['type'],drop_first=True )\n",
    "\n",
    "df=df.drop(['type'], axis=1)\n",
    "df = pd.concat([df, df_dummies], axis=1)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use *HashingEncoder* to handle categorical columns with high cardinality. These cannot be onehotted as that would generate too many columns and a too-sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    " \n",
    "import category_encoders as ce  \n",
    "hashencode_these = ['nameOrig', 'nameDest']\n",
    "columns_before = [x for x in df.columns if x not in hashencode_these+[target_col]]\n",
    "\n",
    "def make_col_mapping(cols):\n",
    "    col_mapping = {}\n",
    "    for c in cols:\n",
    "        if c[:4]=='col_':\n",
    "          num = c.split('_')[-1]\n",
    "          int(num) # check format\n",
    "          col_mapping[c] = hashencode_this + \"_\" + num\n",
    "     \n",
    "    return col_mapping\n",
    "\n",
    "\n",
    "def hashencode(hashencode_this, df, previous_hash_cols):\n",
    "    for c in df.columns:\n",
    "        assert c[:4]!=\"col_\",  df.columns\n",
    "                \n",
    "    ce_hash = ce.HashingEncoder(cols = [hashencode_this])\n",
    "    X1 = df.drop([target_col], axis=1)\n",
    "    y1 = df[target_col]\n",
    "    with_hashing = ce_hash.fit_transform(X1, y1)\n",
    "    hashed = with_hashing.drop(columns_before+previous_hash_cols, axis=1)\n",
    "    generated_cols = [x for x in hashed.columns if x[:4]=='col_']\n",
    "    col_mapping = make_col_mapping(generated_cols)\n",
    "    \n",
    "    hashed = hashed.rename(columns = col_mapping)\n",
    "    df = pd.concat([y1, X1, hashed], axis=1)\n",
    " \n",
    "    df = df.drop([hashencode_this], axis=1)\n",
    "    return df, list(col_mapping.values())\n",
    " \n",
    "previous_hash_cols = []\n",
    "for hashencode_this in hashencode_these: \n",
    "   df, previous_hash_cols = hashencode(hashencode_this,df,previous_hash_cols)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optionally use *SMOTENC* for unbalanced classes, though we may stick with the XGBoost parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "# Using weighting in XGBOOST instead of SMOTENC\n",
    "use_smote = False\n",
    "if use_smote:\n",
    "   ycol=target_col\n",
    "   Xcol=list(df.columns)\n",
    "   Xcol.remove(ycol)\n",
    " \n",
    "   categorical_columns=[i for i in range(len(Xcol)) \n",
    "                     if Xcol[i] not in ['step','amount','oldbalanceOrg','newbalanceOrig','oldbalanceDest','newbalanceDest']]\n",
    "\n",
    "   smotenc = SMOTENC(categorical_columns,random_state = 101)\n",
    "\n",
    "   X, y = smotenc.fit_resample(df[Xcol], df[ycol])\n",
    "   y_df = pd.DataFrame({target_col: y} )\n",
    "\n",
    "   df = pd.concat([X, y_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_positive_negative_counts(df,target_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split  with randomization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "len_=len(df)\n",
    "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=1729), [int(0.7 * len_), int(0.9 * len_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using libSVM for performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import dump_svmlight_file   \n",
    "\n",
    "lengths = [] \n",
    "\n",
    "for d in [(train_data, 'train.libsvm'), ( validation_data, 'validation.libsvm'), (test_data, 'test.libsvm')]:\n",
    "   dataset=d[0]\n",
    "   file_ = d[1]\n",
    "   lengths.append((dataset,len(dataset))\n",
    "   dump_svmlight_file(X=dataset.drop([target_col], axis=1), y=dataset[target_col], f=d[1])\n",
    "\n",
    "print('Length of datasets:', lengths )\n",
    "\n",
    "s3 = boto3.resource('s3', region_name=region)#TODO Remove\n",
    "\n",
    "for filename in ['train.libsvm', 'validation.libsvm']:\n",
    "   s3.Bucket(bucket).Object(prefix + '/'+filename.split('.')[0]+'/'+filename).upload_file(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def s3_path(subset):\n",
    "  return sagemaker.s3_input(s3_data='s3://{}/{}/{}'.format(bucket, prefix,subset), content_type='libsvm')\n",
    "\n",
    "s3_input_train = s3_path('train')\n",
    "s3_input_validation =s3_path('validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Train\n",
    "\n",
    "Our data is now ready to be used to train a XGBoost model. The XGBoost algorithm has many tunable hyperparameters. Some of these hyperparameters are listed below; initially we'll only use a few of them.  \n",
    "\n",
    "- `max_depth`: Maximum depth of a tree. As a cautionary note, a value too small could underfit the data, while increasing it will make the model more complex and thus more likely to overfit the data (in other words, the classic bias-variance tradeoff).\n",
    "- `eta`: Step size shrinkage used in updates to prevent overfitting.  \n",
    "- `eval_metric`: Evaluation metric(s) for validation data. For data sets such as this one with imbalanced classes, we'll use the AUC metric.\n",
    "- `scale_pos_weight`: Controls the balance of positive and negative weights, again useful for data sets having imbalanced classes.\n",
    "\n",
    "First we'll set up the parameters for an Amazon SageMaker Estimator object, and the hyperparameters for the algorithm itself.  The Estimator object from the Amazon SageMaker Python SDK is a convenient way to set up training jobs with a minimal amount of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(region, 'xgboost','1.0-1')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role, \n",
    "                                    base_job_name='fraud-detection-job',\n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.c5.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "                                    sagemaker_session=session)\n",
    "scale_pos_weight=num_negative / num_positive  \n",
    "num_positive, num_negative=count_positive_and_negative(df)\n",
    "\n",
    "print('scale_pos_weight', f'{scale_pos_weight:.1f}')\n",
    "\n",
    "xgb.set_hyperparameters(max_depth=3,\n",
    "                        eta=0.1,\n",
    "                        subsample=0.5,\n",
    "                        eval_metric='auc',\n",
    "                        objective='binary:logistic',\n",
    "                        scale_pos_weight=scale_pos_weight,\n",
    "                        num_round=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the hosted training job itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Host\n",
    "\n",
    "Now that we've trained the XGBoost algorithm on our data, we can deploy the trained model to an Amazon SageMaker hosted endpoint with one simple line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime \n",
    "model = xgb.create_model()\n",
    "container_def = model.prepare_container_def(instance_type='ml.m4.xlarge')\n",
    "model_name = 'fraud' + datetime.datetime.now().isoformat().replace('.','-').replace(':','-')  \n",
    " \n",
    "print('model_name', model_name)\n",
    " \n",
    "session.create_model(model_name, role, container_def)\n",
    "\n",
    "endpoint_config_name = session.create_endpoint_config(name=model_name,\n",
    "                                                      model_name=model_name,\n",
    "                                                      initial_instance_count=1,\n",
    "                                                      instance_type='ml.m5.xlarge')\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "updated_endpoint=client.update_endpoint(EndpointName='fraud-detection-job-2020-11-08-09-33-33-185', EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "#xgb_predictor = xgb.deploy(initial_instance_count=1,\n",
    "#                          instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name='fraud-detection-job-2020-11-08-09-33-33-185'\n",
    "xgb_predictor = sagemaker.predictor.RealTimePredictor(endpoint=endpoint_name, sagemaker_session=sagemaker.Session())\n",
    "\n",
    "print(xgb_predictor)\n",
    "print(type(xgb_predictor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Evaluation\n",
    "\n",
    "Now that we have our hosted endpoint, we can generate predictions from  the  test data set.\n",
    "\n",
    "Compared actual to predicted values of whether the transaction was a \"fraud\" (`1`) or not (`0`).  Then we'll produce a  confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/x-libsvm'\n",
    "xgb_predictor.deserializer = None\n",
    "\n",
    "def do_predict(data):\n",
    "    payload = '\\n'.join(data)\n",
    "    response = xgb_predictor.predict(payload).decode('utf-8')\n",
    "    result = response.split(',')\n",
    "    preds = [float((num)) for num in result]\n",
    "    preds = [round(num) for num in preds]\n",
    "    return preds\n",
    "\n",
    "def batch_predict(data, batch_size):\n",
    "    items = len(data)\n",
    "    arrs = []\n",
    "    \n",
    "    for offset in range(0, items, batch_size):\n",
    "        if offset+batch_size < items:\n",
    "            results = do_predict(data[offset:(offset+batch_size)])\n",
    "            arrs.extend(results)\n",
    "        else:\n",
    "            arrs.extend(do_predict(data[offset:items]))\n",
    "        sys.stdout.write('.')\n",
    "    return(arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import json\n",
    "\n",
    "with open('test.libsvm', 'r') as f:\n",
    "    payload = f.read().strip()\n",
    "\n",
    "labels = [int(line.split(' ')[0]) for line in payload.split('\\n')]\n",
    "test_data = [line for line in payload.split('\\n')]\n",
    "preds = batch_predict(test_data, 100)\n",
    "\n",
    "print ('\\nError rate=%f' % ( sum(1 for i in range(len(preds)) if preds[i]!=labels[i]) /float(len(preds))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=np.array(labels), columns=np.array(preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean up to save money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.delete_endpoint(xgb_predictor.endpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "notice": "Copyright 2017 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
